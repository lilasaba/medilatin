%
%	TSD 2017
%	LaTeX Template for Camera-ready Version
%
%	Rel. 2013-05-20 by Ivan Habernal (habernal@kiv.zcu.cz)
%	Rel. 2014-11-21 by Kamil Ekstein (kekstein@kiv.zcu.cz)
%   Rel. 2015-02-23 by Pavel Kral    (pkral@kiv.zcu.cz)
%	Rel. 2017-02-06 by Kamil Ekstein (kekstein@kiv.zcu.cz)
%
%	Based upon Springer's LNCS series template.
%
\documentclass[runningheads,a4paper]{llncs}

\usepackage{times}
\usepackage{amssymb}
\setcounter{tocdepth}{3}
\usepackage{graphicx}
\usepackage{url}
\usepackage{tipa}

% TSD 2017: Add any additional packages you use in your manuscript
% -----pack
% \usepackage{xxx}
% -----

% TSD 2017: Add your custom definitions etc., if required
% -----misc
% \newcommand{\xxx}[1]{[#1]}
% -----

\newcommand{\keywords}[1]{\par\addvspace\baselineskip
\noindent\keywordname\enspace\ignorespaces#1}

% TSD2017: Put your e-mail addresses here
\urldef{\mailsa}\path|{lili, tfegyo}@speechtex.com|
\urldef{\mailsb}\path|{mihajlik, abalog}@thinktech.hu|
%\urldef{\mailsc}\path|other_mails_if_needed|    

\begin{document}

% TSD 2017: Put your title here (please, use capitalization, see e.g.
% http://en.wikibooks.org/wiki/Basic_Book_Design/Capitalizing_Words_in_Titles)
\title{Unified Simplified Grapheme Acoustic Modeling for Medieval Latin LVCSR}

% TSD 2017: a short form should be given in case the title is too long for the running head
\titlerunning{Medieval Latin LVCSR}

% TSD 2017: Author's names. Chinese authors should write their first names(s)
% in front of their surnames. This ensures that the names appear correctly in
% the running heads and the author index.
% If the names contain accented characters, please use escape codes
% (refer to http://en.wikibooks.org/wiki/LaTeX/Special_Characters#Escaped_codes)
\author{Lili Szab\'{o}\inst{1} \and P\'{e}ter Mihajlik\inst{2,3} \and Andr\'{a}s Balog\inst{2} \and Tibor Fegy\'{o}\inst{1,3}}

% TSD 2017: For authors from different institutions, please use the following
% form including institution reference
% \author{Firstname1 Surname1\inst{1} \and Firstname2 Surname2 \inst{2}}

% TSD 2017: Author's names for headings. For 1-2 authors, use the following form
%\authorrunning{Lili Szab\'{o} \and P\'{e}ter Mihajlik}
% TSD 2017: For more than 2 authors, please, use the following
 \authorrunning{Lili Szab\'{o} et al.}

% TSD 2017: The authors' affiliations
\institute{SpeechTex Ltd.\\
% TSD 2017: optional url
\url{www.speechtex.com} \\
\mailsa\\
% TSD 2017: For authors from different institutions, add 2nd institution, etc.
\and
ThinkTECH Research Center \\
\mailsb\\
% \url{www.website.org} \\
\and
Budapest University of Technology and Economics
}

% TSD 2017: Put all authors' names to the proceeding index (surname, first name)
\index{Szab\'{o}, Lili}
\index{Mihajlik, P\'{e}ter}
\index{Balog, Andr\'{a}s}
\index{Fegy\'{o}, Andr\'{a}s}

\toctitle{} \tocauthor{}

\maketitle

%
%
%	TSD2017 SUBMISSION TEXT
%
%
\begin{abstract}
% TSD 2017:
%TODO: revise according to new PL results!
A large vocabulary continuous speech recognition (LVCSR) system designed for dictation of medieval Latin language documents is introduced.
Such language technology tool can be of great help for preserving Latin language charters from this era, as optical character recognition systems are often challenged by these historical materials.
As corresponding historical research focuses on the Visegrad region, our primary aim is to make medieval Latin dictation available for texts and speakers of this region, concentrating on Czech, Hungarian and Polish.
The baseline acoustic models we start with are monolingual grapheme-based ones. 
On one hand, the application of medieval Latin knowledge-based grapheme-to-phoneme (G2P) mapping from the source language to the target language resulted in significant improvement, reducing the Word Error Rate (WER) by $13.3\%$. 
On the other hand, applying a Unified Simplified Grapheme (USG) inventory set for the three-language acoustic data set complemented with Romanian speech data, resulted in a further $0.7\%$ WER reduction - without using any target or source language G2P rules.
% TSD 2017: keywords, comma-separated
\keywords{G2P, medieval Latin, under-resourced speech recognition, unified simplified grapheme modeling}
\end{abstract}

\section{Introduction}
The pronunciation of Latin texts mainly depends on the era and region of their origin~\cite{regional}.
Apart from the two widely studied classical and ecclesiastical pronunciation styles~\cite{allen78}, many other regional pronunciations exists that emerged after the classical era.
One of these pronunciation groups is the East-Central European ~\cite{regional} one, described in detail in Section~\ref{g2p}.
Although the target pronunciation is considered to be uniform for this group, it also has to be taken into account, that the acoustic base of the different source languages varies, which can lead to various accents.
It also has to be noted, that apart from the variations in the pronunciations, orthographic and grammatical variations of Latin are also exhibited through regions.

This raises the question of how to create a speech recognition system which has to deal with pronunciation variations of native speakers of different languages reading linguistically different texts.
We propose a system built for the recognition of medieval Latin speech spoken by speakers from the Visegrad region.
It is also important to collect in-domain textual/language data for the language model from the relevant geographican regions and time.
We describe the data acquisition process in Section~\ref{text}.

Our baseline system consists of separately trained grapheme-based acoustic models for three of the Visegrad languages (Czech, Hungarian, Polish) complemented with the Romance language Romanian.
We apply two different acoustic/pronunciation modeling techniques to develop models that are superior to the baseline.
The first one, discussed in detail in Section~\ref{g2p}, is a knowledge-based pronunciation modeling technique, where the source language phonemes are mapped to the target language phonemes.
The second method applied is a Unified Simplified Grapheme (USG) acoustic modeling approach, where a joint grapheme inventory is established for all the languages participating in the joint acoustic model training, described in Section~\ref{usg}.
The evaluation of all systems is presented in section~\ref{results}.

\subsubsection{Related work}
Different adaptation techniques have been proposed in~\cite{schultz01} and \cite{besacier14}to train acoustic models from multiple source languages for a single target language where training data was limited.
Similar work has been done for multi-dialectal languages such as Arabic in~\cite{elfeky16} where jointly trained acoustic models were outperformed by methods that unify dialect specific-acoustic models using knowledge distillation and multitask learning.
However, no approach is known for the authors where the graphemes of multiple languages are merged successfully and applied for acoustic modeling of a different language.
To our knowledge, no previous work has been done on medieval Latin speech recognition, nor on classical Latin for that matter.

\section{Data}
\subsection{Textual data}\label{text}
As part of our inquiry was to cover linguistic variability across the Visegrad region, aquiring textual data posed a few challenges.
First of all, textual data are scarce for medieval Latin, and texts originating from this geographical region are even more difficult to obtain in electronic format.
Additionally, most of the available sources mix local languages and Latin, with no metadata to separate them.
For the scope of this paper, we collected monolingual (Latin) texts only.
\subsubsection{Training data}\label{traintext}
A smaller amount of in-domain data (medieval charters) were collected from~\cite{monasterium} (Monasterium), with an overall of 480k tokens.
These documents are originating from the Hungarian Kingdom, from 1000 to 1524 AD.
To increase the vocabulary size of the language model, we collected a relatively larger (but still small, compared to state-of-the-art language models used in speech recognition) 1.3M-token corpus from~\cite{latinlibrary} (LatinLibrary).
This corpus consists of literary and historical texts from the post-classical era.
In spite of our efforts, at the time of writing this paper, we could not gather a measurable amount of textual data from the age and area of the Kingdoms of Bohemia and Poland.
\subsubsection{Test data}\label{testtext}
Using independent sources, three charters were selected from the Kingdoms of Bohemia (CZ), Hungary (HU) and Poland (PL), from around 1200-1300 AD, as test data for evaluating the language model, and to test the performance of the LVCSR approaches.
The test sets were read out loud by historians fluent in medieval Latin.
\subsubsection{Alternate spellings}
One interesting feature of the acquired corpora is that they contain a significant number of spelling variants.
Having spelling variants in the corpus with identical pronunciation introduces noise, and thus has a negative effect on recognition results.
To detect the spelling variants we took all pairs in the pronunciation dictionary whose pronunciation were identical, and used context and expert knowledge to decide whether the pair of equivalent pronunciations are spelling variants or homophones.
We obtained a unified spelling for these variants by favouring the more frequent variant in the corpus (e.g. \textit{maiestati} to \textit{majestati}).
Resolving spelling variants resulted in a more consistent corpus in terms of perplexity (reducing it from 775 to 672), and reduced the OOV rate by 0.8\%.
\subsubsection{Language model}
The word trigram language models we built from the two corpora were estimated with the SRI Language Modeling toolkit (SRILM)~\cite{srilm} using modified Kneser-Ney smoothing method.
After estimating the mixture parameter, linear interpolation was used to merge the two language models.

The perplexity measures on the test data showed that the Monasterium corpus originating from the time and era of the Hungarian Kingdom was indeed best fitting with the Hungarian subset of the test data with a perplexity of 82, and an OOV rate of $0.9\%$.
The perplexities measured on the Czech and Polish origin text sets were ranging from 500 to 3200.
Adding the LatinLibrary corpus increased the perplexity significantly (up to 672), but reduced the OOV rate by $7\%$ on the overall test data, as well as the WER, so we decided to use the interpolated language model.

\subsection{Speech data}
\subsubsection{Training data}\label{speechtraining}
For Czech, the read part of Speecon database~\cite{czech} was used, 76 hours in sum.
For Hungarian, beyond Speecon~\cite{hungarian}, manually transcribed broadcast news (112 hours) and conversational speech data was used, altogether 567 hours.
With the exception of the Hungarian knowledge-based model (described in Section~\ref{g2p}), the 112-hour broadcast news set was used for training.
For Polish, only broadcast news data~\cite{romanian} was available, comprising 31 hours of manually transcribed speech.
The Romanian speech database used for the experiments was originally collected for~\cite{romanian} consisting of 35 hours of broadcast news.
\subsubsection{Test data}
Native speakers of Czech, Hungarian, Polish and Slovakian - all of whom have experince with medieval Latin - were asked to record the three test sets described in Section~\ref{testtext}.
The recording conditions were accurately controlled: close-talking microphones, quiet, non reverberant acoustic environment, fluent, flawless speech, and at least 16 kHz, 16 bit (linear PCM) encoding.
No instructions were given regarding the pronunciation, the speakers were using their expertise on medieval Latin pronunciation - affected certainly by their native language.
The overall length of the recorded test speech was around 30 minutes.

\section{Acoustic modeling}\label{AM}
Building an acoustic model for speech recognition requires long hours of transcribed speech.
As of today (medieval) Latin is not spoken natively, and as to our knowledge, there is no recorded speech database.
One obvious way to handle this problem is by creating a medieval Latin database; a proposition that requires lot of time, resources and trained speakers of medieval Latin. 
Another way of circumventing the lack of available speech data is to use speech data of spoken languages, preferably those ones whose native speakers are going to use the system. 

For all the different pronunciation modeling methods, the acoustic models were trained as follows.
Mel-Frequency Cepstrum $+$ Energy features were used with Linear Discriminant Analysis (LDA) + Maximum Likelihood Linear Transformation (MLLT), with a splice context of $\pm4$ frames, 10 ms of frame shift.
$9\times40$ dimensional spliced up feature vectors served as input to the feed-forward, 6 hidden-layer neural network with p-norm~\cite{kaldi} activation function.
Prior to DNN training, a Gaussian Mixture Model (GMM) pre-training was performed.
Clustering and Regression Tree (CART)~\cite{kaldi} was applied to obtain across‒word context dependent shared state phone (or graph) models and their time alignment.
The number of senones (and so the size of the DNN softmax output layer) was between 7.000 and 11.000 depending on the nature of the training data.
The size of the hidden layers was kept constantly on 2.000.
A minibatch size of 512, an initial learning rate of 0.1, and final learning rate of 0.01 was applied in 20 epochs using the Kaldi toolkit~\cite{kaldi}.

\subsection{Grapheme-based pronunciation modeling}\label{baseline}
For our three separately trained baseline systems, grapheme-based acoustic models were used where pronunciation is modeled in an implicit way.
The language-specific graphemes (e.g. \texttt{\"{o}}, \texttt{\'{n}}) that are not part of the Latin alphabet were trained, but not used in the recognition phase.

\subsection{Source-target grapheme to phoneme mapping (G2P)}\label{g2p}
This method utilizes already trained acoustic models where the source language phonemes are mapped to the target language phonemes using expert knowledge.
The source language acoustic models are trained with with G2P mapping from orthographic transcriptions to native phonemes.
In our experiment we used Czech and Hungarian as (separately trained) source languages for the target language Latin.
After mapping source language phonemes to Latin phonemes, Latin-specific pronunciation rules were implemented.
These include a set of context independent digraph mappings and context dependent rewrite rules, summarized in Table~\ref{tbl:digraph} and Table~\ref{tbl:context} respectively, for both Czech and Hungarian.
Both languages fully cover the phoneme inventory of medieval Latin which is of size 24.

\begin{table}
	\centering
	\caption{Latin digraph context-insensitive rewrite rules.}\label{tbl:digraph}
	\begin{tabular}{l|rrrr}
	\hline
	& \multicolumn{4}{c}{Digraph} \\
	\hline
	   & ae & oe & ph & qu \\
	\hline
	CZ & e & oe & f & kv \\
	HU & e & \o & f & kv \\
	\hline
	\end{tabular}
\vspace*{0.4 cm}
	\centering
	\caption{Latin context-sensitive rewrite rules. V: vowel, VP: palatal vowel, \string^VP: everything but a palatal vowel, C: consonant, $*$: zero or any, \string^: beginning of word, $[\string^stx]$: not s, t or x.}\label{tbl:context}
	\begin{tabular}{l|cc|cc|cc|cc}
	\hline
	GR & c & c & ch & ch & gu & gu & ti & ti \\
	PH & ts & k & h & k & gv & gu & tsi & ti \\
	\hline
	rule & \multicolumn{1}{c|}{cVP} & \multicolumn{1}{c|}{c\string^VP} & \multicolumn{1}{c|}{VC*ch} & \multicolumn{1}{c|}{\string^C*ch} & \multicolumn{1}{c|}{guV} & \multicolumn{1}{c|}{guC} & \multicolumn{1}{c|}{$[\string^stx]$tiV} & \multicolumn{1}{c|}{tiC} \\
	\hline
	\end{tabular}
\end{table}

\subsection{Unified Simplified Grapheme Acoustic Modeling}\label{usg}
The second method used for improving speech recognition of medieval Latin - this time in a fully data driven way - was the Unified Simplified Grapheme (USG) acoustic modeling technique.
Our motivation with using this technique was three-fold:
\begin{enumerate}
\item Develop a target language acoustic model using available language resources.
\item Support recognition of medieval Latin spoken by speakers of diverse native language background.
\item As the writing systems in the Visegrad region are originating from medieval Latin, we were aiming to validate the intuition that by unifying and simplifying the native graphemes, the deviations from the common ancestor cancel out.
\end{enumerate}
We experimented with joint three- and four-language USG acoustic models of any combination of the four languages (Czech, Hungarian, Polish and Romanian). 
The joint acoustic model requires a unified grapheme inventory for the training.
Our proposal was to simplify all special characters, i.e. those graphemes that had a diacritic mark (acute, caron, etc.) on them, were mapped back to their normalized form.
Table~\ref{tbl:usg-examples} contains examples for the unification/simplification process for all four languages.
For the four languages an overall of 32 of such unifications/simplifications were made, reducing the unified grapheme inventory set from 58 to 26.
Further than that, those graphemes that are non-native to Latin, and can straightforwardly mapped to a native Latin grapheme(s), were also replaced.
These included mappings from \texttt{x} to \texttt{ks}, \texttt{y} to \texttt{i} and \texttt{w} to \texttt{v}.
%That way the graphemic transcription of the word \texttt{taxi} becomes \texttt{/t~a~ks~i/}.
As a result, a unified and simplified grapheme inventory set was produced, formally compatible with medieval Latin.
The USG units were then used as acoustic model units in the multiple language training.

\begin{table}
	\centering
	\caption{Simplification examples for the unified model.}\label{tbl:usg-examples}
	\begin{tabular}{l|rrrr}
	\hline
	Language & CZ & HU & PL & RO \\
	\hline
	Orthographic & \v{r}ekl & \H{o}z & mi\'{s} & ap\u{a} \\
	USG & rekl & oz & mis & apa \\
	\hline
	\end{tabular}
\end{table}

\section{Experimental results}\label{results}
We conducted experiments on medieval Latin, spoken by native speakers of four languages (Czech, Hungarian, Polish and Slovakian), where the test texts were originating from different regions, as described in Sections~\ref{AM}~and~\ref{text}.
The best performing monolingual grapheme-based model results were that of Hungarian, with $34.6\%$ overall WER (see in Table~\ref{tbl:cz_hu_pl_ro_grapheme}), possibly because of the larger training data - this was the reference value when comparing the results.
On a related note, we also found that except for Czech, each monolingual grapheme-based acoustic model had the best performance over its own test set.

\begin{table}
\centering
\caption{Word Error Rate (WER[\%]) results for monolingual grapheme-based acoustic models of Czech, Hungarian, Polish and Romanian (CZ, HU, PL, RO).}
\input{tables/cz_hu_pl_ro_grapheme.tex}\label{tbl:cz_hu_pl_ro_grapheme}
\end{table}

\subsection{Source-target G2P mapping results}
The results on the experiments with the knowledge-based pronunciation modeling technique, where the native phonemes of the source phoneme-based acoustic models were mapped to the target phonemes in the pronunciation dictionary, are in Table~\ref{tbl:cz_phoneme} for the source language Czech, and in Table~\ref{tbl:hu_phoneme} for the source language Hungarian.
The Hungarian knowledge-based acoustic model significantly outperforms the (Hungarian grapheme-based) baseline, with an $21.1\%$ overall WER.
It is worth mentioning that the Czech and Slovakian speaker test sets achieve a surprisingly low $6.4\%$ and $9.1\%$ WER respectively on the Hungarian text test set.

\begin{table}
\parbox{.45\linewidth}{
\centering
\caption{WER[\%] for Latin-Czech source-target G2P model. Acoustic model training set: 76 hours.}
\input{tables/cz_phoneme.tex}\label{tbl:cz_phoneme}
}
\hfill
\parbox{.45\linewidth}{
\centering
\caption{WER[\%] for Latin-Hungarian source-target G2P model. Acoustic model training set: 567 hours.}
\input{tables/hu_phoneme.tex}\label{tbl:hu_phoneme}
}
\end{table}

\subsection{USG results}
The results for the three-language joint acoustic models are in Table~\ref{tbl:three_language_usg}.
Among the three-language USG models, the Czech-Hungarian-Romanian model had the best performance with a competitive overall $21.9\%$ WER. 
When adding Romanian, we got the best experimental results of $20.4\%$ with the four-language USG model (see in Table~\ref{tbl:cz_hu_pl_ro_usg}).
We also measured the WER on any combination of three of the four languages, and found that each language contributed to the four-language model.

It is worth mentioning, that compared to the knowledge-based Hungarian model (Table~\ref{tbl:hu_phoneme}), the results on the Polish speaker test set improved by a significant $6.5\%$ (absolute).
This could be due to the ability of the four-language model to generalize better over different speaker test tests.
This generalizing ability intensifies when adding training data of a new language, as the models of similar graphemes are merged, and work better on different native language speaker test sets.

\begin{table}
\parbox{.45\linewidth}{
\centering
\caption{WER[\%] for all the three-language USG models.}
\input{tables/three_language_usg.tex}\label{tbl:three_language_usg}
}
\hfill
\parbox{.45\linewidth}{
\centering
\caption{WER[\%] for USG model of Czech, Hungarian, Polish and Romanian (CZ+HU+PL+RO).}
\input{tables/cz_hu_pl_ro_usg.tex}\label{tbl:cz_hu_pl_ro_usg}
}
\end{table}
The most striking results in Tables~\ref{tbl:hu_phoneme}~and~\ref{tbl:cz_hu_pl_ro_usg} were that all but the Hungarian speaker test sets performed better on the Hungarian text test set.
We had expected the Hungarian speakers to perform better with the Hungarian knowledge-based model and Hungarian text test set setting, but in fact the phoneme mapping masked the difference between mid-front \texttt{/e:/} and open-front \texttt{/\textipa{E}/} in the pronunciation of the Hungarian speakers.
In addition to that, they were pronouncing the named entities using their native pronunciation, which also increased the WER.

Similarly, the results on the Hungarian speaker test set also improved by $3\%$ (absolute) with the four-language USG model compared to the knowledge-based Hungarian model in Table~\ref{tbl:hu_phoneme}.
This was supposedly also because the pronunciation of the Hungarian speakers deviated from the one defined in the knowledge-based model, and the four-language model was able to generalize better. 

Finally, the results show that the experiments conducted on the Hungarian origin text test set yielded to the best results with all models.
This is due to the fact that the in-domain part of the language model training data was originating from the Hungarian language region, see Section~\ref{traintext}.
\subsection{Conclusions}
In this paper, we introduced two acoustic modeling techniques for a target language independent medieval Latin speech recognizer to elevate the efforts of digitizing medieval Latin charter data.
Our goal was to build an acoustic model for medieval Latin, borrowing speech data from different source languages (Czech, Hungarian, Polish and Romanian).
Our test set consisted of medieval Latin charters originating from different regions read by native speakers of the above languages.
With the objective of building an acoustic model without source language speech data, we presented two approaches: knowledge-based G2P modeling, and USG modeling.

The results showed that both methods outperform by far the best baseline system. 
We found that the best model was the four-language USG model.
When comparing it to the knowledge-based Hungarian phoneme-based model, which was using expert knowledge to map words to phoneme sequences, and trained on larger amount of data, it seemed that the four-language USG model was better in evening out the inconsistencies of the pronunciations in different speaker test sets.

Future research directions include acquiring a considerable amount of medieval speech and textual data, as well as implementing a more refined G2P modeling using a unified phoneme inventory set.
Furthermore, adding more data when using the USG approach may result in even higher recognition accuracy, allowing dictational applications.

% Bibliography
\bibliographystyle{splncs03}
\bibliography{tsd2017}

\end{document}
