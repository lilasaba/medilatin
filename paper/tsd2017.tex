%
%	TSD 2017
%	LaTeX Template for Camera-ready Version
%
%	Rel. 2013-05-20 by Ivan Habernal (habernal@kiv.zcu.cz)
%	Rel. 2014-11-21 by Kamil Ekstein (kekstein@kiv.zcu.cz)
%   Rel. 2015-02-23 by Pavel Kral    (pkral@kiv.zcu.cz)
%	Rel. 2017-02-06 by Kamil Ekstein (kekstein@kiv.zcu.cz)
%
%	Based upon Springer's LNCS series template.
%
\documentclass[runningheads,a4paper]{llncs}

\usepackage{times}
\usepackage{amssymb}
\setcounter{tocdepth}{3}
\usepackage{graphicx}
\usepackage{url}
\usepackage{tipa}

% TSD 2017: Add any additional packages you use in your manuscript
% -----pack
% \usepackage{xxx}
% -----

% TSD 2017: Add your custom definitions etc., if required
% -----misc
% \newcommand{\xxx}[1]{[#1]}
% -----

\newcommand{\keywords}[1]{\par\addvspace\baselineskip
\noindent\keywordname\enspace\ignorespaces#1}

% TSD2017: Put your e-mail addresses here
\urldef{\mailsa}\path|{author1, author2}@institute1.org|
\urldef{\mailsb}\path|author3@institute2.org|
%\urldef{\mailsc}\path|other_mails_if_needed|    

\begin{document}

% TSD 2017: Put your title here (please, use capitalization, see e.g.
% http://en.wikibooks.org/wiki/Basic_Book_Design/Capitalizing_Words_in_Titles)
\title{Unified Simplified Grapheme Acoustic Modeling for Medieval Latin LVCSR}

% TSD 2017: a short form should be given in case the title is too long for the running head
% ne felejstük update-elni majd.
\titlerunning{Medieval Latin LVCSR}

% TSD 2017: Author's names. Chinese authors should write their first names(s)
% in front of their surnames. This ensures that the names appear correctly in
% the running heads and the author index.
% If the names contain accented characters, please use escape codes
% (refer to http://en.wikibooks.org/wiki/LaTeX/Special_Characters#Escaped_codes)
\author{Firstname1 Surname1 \and Firstname2 Surname2 \and Firstname3 Surname3}

% TSD 2017: For authors from different institutions, please use the following
% form including institution reference
% \author{Firstname1 Surname1\inst{1} \and Firstname2 Surname2 \inst{2}}

% TSD 2017: Author's names for headings. For 1-2 authors, use the following form
\authorrunning{Firstname1 Surname1 and Firstname2 Surname2}
% TSD 2017: For more than 2 authors, please, use the following
% \authorrunning{Name1 Surname1 et al.}

% TSD 2017: The authors' affiliations
\institute{Affiliation1, Institute1, Address \\
% TSD 2017: optional url
\url{www.website.org} \\
\mailsa\\
% TSD 2017: For authors from different institutions, add 2nd institution, etc.
% \and
% Affiliation2, Institute2, Address \\
% \url{www.website.org} \\
% \mailsb\\
}

% TSD 2017: Put all authors' names to the proceeding index (surname, first name)
\index{Surname1, Firstname1}
\index{Surname2, Firstname2}

\toctitle{} \tocauthor{}

\maketitle

%
%
%	TSD2017 SUBMISSION TEXT
%
%
\begin{abstract}
% TSD 2017:
%TODO: revise according to new PL results!
A large vocabulary continuous speech recognition (LVCSR) system designed for dictation of medieval Latin language documents is introduced.
Such language technology tool can be of great help for preserving Latin language charters from this era, as optical character recognition systems are often challenged by these historic materials.
As corresponding historical research focuses on the Visegrad region, our primary aim is to make medieval Latin dictation available for texts and speakers of this region, concentrating on Czech, Hungarian and Polish.
The baseline acoustic models we start with are monolingual grapheme-based ones. 
In one hand, the application of medieval Latin knowledge-based grapheme-to-phoneme (G2P) mapping from the source language to the target language resulted in significant improvement, reducing the Word Error Rate (WER) by $13.3\%$. 
On the other hand, applying a unified-simplified grapheme (USG) inventory set for the three-language acoustic data set complemented with Romanian speech data yielded in competitive results - without using any target or source language G2P rules.
% TSD 2017: keywords, comma-separated
\keywords{G2P, medieval Latin, under-resourced speech recognition, unified simplified grapheme modeling}
\end{abstract}

\section{Introduction}
The pronunciation of Latin texts mainly depends on the era and region of their origin~\cite{regional}.
Apart from the two widely studied classical and ecclesiastical pronunciation styles~\cite{allen78}, regional pronunciations emerged after the classical era.
One of these pronunciation groups is the east-central european ~\cite{regional} one, which uses roughly the same pronunciation rules, described in detail in Section~\ref{g2p}.
Although the target pronunciation is considered to be uniform for this group, it is also has to be taken into account, that the acoustic base of the different source languages varies, which can lead to various accents.
It also has to be noted, that apart from the variations in the pronunciations, orthographic and grammatical variations of Latin are also exhibited through regions.

This raises the question of how to create a speech recognition system which has to deal with pronunciation variations for native speakers of different languages reading linguistically different texts.
We propose a system that aimes at the recognition of medieval Latin speech spoken by speakers from the Visegrad region.
Therefore, it is important to collect in-domain textual/language data for the language model from the relevant geographican regions and time.
We describe the data acquisition process in section~\ref{text}.

Our baseline system consists of separately trained grapheme-based acoustic models for three of the Visegrad languages (Czech, Hungarian, Polish) complemented with the Romance language Romanian.
We apply two different acoustic/pronunciation modeling techniques to develop models that are superior to the baseline.
The first one, dicussed in detail in Section~\ref{g2p}, is a knowledge-based pronunciation modeling technique, where the source language phonemes are mapped to the target language phonemes.
The second method applied is a unified simplified grapheme (USG) acoustic modeling approach, where a joint grapheme inventory is established for all the languages paricipating in the joint acoustic model training.
We describe the USG method in Section~\ref{usg}.
Evaluation of the baseline systems and both above approaches is presented in section~\ref{results}.

\subsection{Related work}
%TODO: \cite{schultz01}
Different adaptaion techniques have been proposed in~\cite{schultz01} to train acoustic models from multiple source languages for a single target language where training data was limited.
%TODO: \cite{besacier14}
\cite{besacier14} gives a great overview on designing speech recognition systems for under-resourced languages.
Similar work has been done for multi-dialectal languages such as Arabic in~\cite{elfeky16} where jointly trained acoustic models were outperformed by methods that unify dialect specific-acoustic models using knowledge distillation and multitask learning.
However, no  approach is known for the authors where the graphemes of multiple languages are merged succesfully and applied for acoustic modeling of a different language.
To our knowledge, no previous work has been done on medieval Latin speech recognition, nor on classical Latin for that matter.
%TODO: mention espeak TTS? - No.

\section{Data}
\subsection{Textual data}\label{text}
As part of our inquiry was to cover linguistic variability accross the Visegrad region, aquiring textual data posed a few challenges.
First of all, textual data are scarce for medieval Latin, and texts originating from this geographical region are even more difficult to obtain in electronic format.
Additionally, most of the available sources mix local languages and Latin, with no metadata to separate them.
For the scope of this paper, we collected monolingual (Latin) texts only.
\subsubsection{Training data}\label{traintext}
A smaller amount of in-domain data (medieval charters) were collected from~\cite{monasterium} (Monasterium), with an overall of 480k tokens.
These documents are originating from the Hungarian Kingdom, from 1000 to 1524 AD.
To increase the vocabulary size of the language model, we collected a relatively larger (but still small, compared to state-of-the-art language models used in speech recognition) 1.3M-token corpus from~\cite{latinlibrary} (LatinLibrary).
This corpus consists of literary and historical texts from the post-classical era.
In spite of our efforts, at the time of writing this paper, we could not gather textual data from the age and area of the Kingdoms of Bohemia and Poland.
\subsubsection{Test data}\label{testtext}
Using independent sources, three charters were selected from the Kingdoms of Bohemia (CZ), Hungary (HU) and Poland (PL), from around 1200-1300 AD, for development and test data.
The dev set was used for evaluating the language model, and to test the performance of the LVCSR approaches.
Both dev and test sets were read out loud by historians fluent in medieval Latin.
\subsubsection{Alternate spellings}
One interesting feature of the acquired corpora is that they contain a significant number of spelling variants.
Having spelling variants in the corpus with identical pronunciation introduces noise, and thus has a negative effect on recognition results.
To detect the spelling variants we took all pairs in the pronunciation dictionary whose pronunciation were identical, and used context and expert knowledge to decide whether the pair of equivalent pronunciations are spelling variants or homophones.
We obtained a unified spelling for these variants by favouring the more frequent variant in the corpus (e.g. \textit{maiestati} to \textit{majestati}).
Resolving spelling variants resulted in a more consistent corpus in terms of perplexity (reducing it from 775 to 672), and reduced the OOV rate by 0.8\%.
%TODO: verbatim text excerpts (cz).
\subsubsection{Language model}
The word trigram language models we built from the two corpora were estimated with the SRI Language Modeling toolkit (SRILM)~\cite{srilm} using modified Kneser-Ney smoothing method.
After estimating the mixture parameter, linear interpolation was used to merge the language models of the two text corpora.

The perplexity measures on the dev data showed, that the Monasterium corpus originating from the time and era of the Hungarian Kingdom was indeed best fitting with the Hungarian subset of the test data with a perplexity of 82, and an OOV rate of $0.9\%$.
Adding the LatinLibrary corpus increased the perplexity significantly, but reduced the OOV rate by $7\%$ on the overall test data, as well as the WER, so we decided to use the interpolated language model.

\subsection{Speech data}
\subsubsection{Training data}
For Czech, the read part of Speecon database ~\cite{czech} was used, 76 hours in sum. For Hungarian, beyond Speecon ~\cite{hungarian}, manually transcribed broadcast news (112 hours) and conversational speech data was used, altogether 567 hours.
For Polish, only broadcast news data~\cite{romanian} was available, comprising 31 hours of manually transcribed speech.
The Romanian speech database used for the expriments was originally collected for~\cite{romanian} consisting of 35 hours of broadcast news.
\subsubsection{Test data}
Native speakers of Czech, Hungarian, Polish and Slovakian - all of whom have experince with medieval Latin - were asked to record the three dev and test sets described in Section~\ref{testtext}.
The recording conditions were accurately controlled: close‒talking microphones, quiet, non reverberant acoustic environment, fluent, flawless speech, and at least 16 kHz, 16 bit (linear PCM) encoding.
No instructions were given regarding the pronunciation, the speakers were using their expertise on medieval Latin pronunciation - affected certainly by their native language.
The overall length of the recorded test speech was around 30 minutes.

\section{Acoustic modeling}\label{AM}
Building an acoustic model for speech recognition requires long hours of trancribed speech.
As of today (medieval) Latin is not spoken natively, and as to our knowledge, there is no recorded speech database.
One obvious way to handle this problem is create a medieval Latin database; a proposition that requires lot of time, resources and trained speakers of medieval Latin. 
Another way of circumvent the lack of available speech data is to use speech data of spoken languages, preferably those ones whose native speakers are going to use the system. 

For all the different pronunciation modeling methods, the acoustic models were trained as follows.
Mel-Frequency Cepstrum $+$ Energy features were used with Linear Discriminant Analysis (LDA) + Maximum Likelihood Linear Transformation (MLLT), with a splice context of $\pm4$ frames, 10 ms of frame shift.
$9\times40$ dimensional spliced up feature vectors served as input to the feed‒forward, 6 hidden‒layer neural network with p‒norm [16] activation function.
Prior to DNN training, a Gauss Mixture Model (GMM) pre-training was performed.
Clustering and Regression Tree (CART)~\cite{kaldi} was applied to obtain across‒word context dependent shared state phone (or graph) models and their time alignment.
The number of senones (and so the size of the DNN softmax output layer) was between 7.000 and 11.000 depending on the nature of the training data.
The size of the hidden layers was kept constantly on 2.000.
A minibatch size of 512, an initial learning rate of 0.1, and final learning rate of 0.01 was applied in 20 epochs using the KALDI toolkit~\cite{kaldi}.
\subsection{Grapheme-based pronunciation modeling}\label{baseline}
For our three separately trained baseline systems, grapheme-based acoustic models were used where pronunciation is modeled in an implicit way.
The same principles - described in detail in Section~\ref{usg} - are applied, namely, mapping the graphemes not present in the Latin grapheme set to their normalized (simplified) counterparts.
\subsection{Source-target grapheme to phoneme mapping (G2P)}\label{g2p}
As source language acoustic training data, Czech and Hungarian phoneme-based acoustic models were used with G2P mapping from orthographic transcriptions to native phonemes.
To develop a pronunciation dictionary for the target language medieval Latin, first we mapped source languages phonemes to target language phonemes using expert knowledge.
As a second step, Latin-specific pronunciation rules also had to be mplemented.
These include a set of context independent digraph mappings and context dependent rewrite rules, summarized in Table~\ref{tbl:digraph} and Table~\ref{tbl:context} respectively, for both Czech and Hungarian.
Both languages fully cover the phoneme inventory of medieval Latin.
The Latin alphabet, extracted from our corpora (see Section~\ref{text}), consisted of 24 elements.

\begin{table}
	\centering
	\caption{Latin digraph context-insensitive rewrite rules.}\label{tbl:digraph}
	\begin{tabular}{l|rrrr}
	\hline
	Digraph & ae & oe & ph & qu \\
	\hline
	CZ & e & oe & f & kv \\
	HU & e & \o & f & kv \\
	\hline
	\end{tabular}
\end{table}

\begin{table}
	\centering
	\caption{Latin context-sensitive rewrite rules. V: vowel, VP: palatal vowel, C: consonant, $*$: zero or any, \string^: beginning of word, $[\string^stx]$: not s, t or x.}\label{tbl:context}
	\begin{tabular}{l|cc|cc|cc|cc}
	\hline
	GR & c & c & ch & ch & gu & gu & ti & ti \\
	PH & ts & k & h & k & gv & gu & tsi & ti \\
	\hline
	rule & \multicolumn{1}{c|}{cVP} & \multicolumn{1}{c|}{VNP} & \multicolumn{1}{c|}{VC*ch} & \multicolumn{1}{c|}{\string^C*ch} & \multicolumn{1}{c|}{guV} & \multicolumn{1}{c|}{guC} & \multicolumn{1}{c|}{$[\string^stx]$tiV} & \multicolumn{1}{c|}{tiC} \\
	\hline
	\end{tabular}
\end{table}

%The G2P rules were composed with the language model within a WFST framework~\cite{wfst}.
%The interpolated LM described in Section 2.1 was composed with the appropriate phoneme or grapheme based pronunciation dictionaries in the Weighted finite State Transducer (WFST) framework [17]. After the usual optimization processes the WFST recognition network translates between generalized triphones (or trigraphs) and words. 
%The mapping of triphones (trigraphs) to senones was performed in the VoXerver WFST‒HMM‒DNN decoder. Approximately the same speed, faster than real‒time decoding was performed in all experiments.
\subsection{Unified Simplified Grapheme Acoustic Modeling}\label{usg}
The second method used for improving speech recognition of medieval Latin - this time in a fully data driven way - was the Unified Simplified Grapheme (USG) acoustic modeling technique.
Our motivation with using this technique was three-fold:
\begin{enumerate}
\item Develop a target language acoustic model using available language resources.
\item Support recognition of medieval Latin spoken by speakers of a diverse native language background.
\item Validate the intuition that - since the writing systems of the Countries of Visegrad region are based on Latin - the deviations from the common ancestor (medieval Latin) are extinguishable through unifications and simplifications of the national graphemes.
\end{enumerate}
%It is motivated by the intuition that ...
So, we used a joint grapheme acoustic model of Czech, Hungarian and Polish and its completion with Romanian was also investigated. 
% We chosed grapheme instead of phoneme as the basis of joint acoustic model because G2P was not available for the half of the languages.

The joint acoustic model requires a unified grapheme inventory for the trainig, so that the graphemes are in the intersection of the different grapheme inventory sets of the training languages need special treatment.
These graphemes are mapped to their normalized forms, e.g. it had a diacritic mark (acute, caron, etc.) on it, we mapped it back to its simplified (normalized) form (\texttt{\v{r}} to \texttt{r}, \texttt{\'{o}} to \texttt{o}, etc.).
Further than that, those graphemes that are non-native to Latin, and can straightforwardly mapped to a native Latin grapheme(s), were also replaced.
These are mappings from \texttt{x} to \texttt{ks}, \texttt{y} to \texttt{i} and \texttt{w} to \texttt{v}.
As a result, a unified and simplified grapheme inventory set was produced, formally compatible with medieval Latin.
The USG units were then used as acoustic model units in the training.
\section{Experimental results}\label{results}
We conducted experiments on medieval Latin, spoken by native speakers of four languages (Czech, Hungarian, Polish and Slovakian), where the test texts were originating from different regions, as described in Sections~\ref{AM}~and~\ref{text}.

It can be noticed on Table 4 and 5 that the experiments conducted on the Hungarian origin text test set yielded to the best results with all models.
This is due to the fact, that the in-domain part of the language model training data was originating from the Hungarian language region see Section~\ref{traintext}.
% ezt ellenőrizni és revidiálni kell az új eredmények szerint:
On a related note, we also found that except for Polish, the baseline acoustic models were yielding the best results when testing with native speakers of the source language.

The best performing monolingual grapheme-base model results were that of Hungarian, with $42.0\%$ overall WER (see in Table~\ref{tbl:cz_hu_pl_ro_grapheme}), possibly because of the highest amount of training data - this was the reference value when comparing the results.
\begin{table}
\centering
\caption{Word Error Rate (WER[\%]) results for monolingual grapheme-based models of Czech, Hungarian, Polish and Romanian (CZ, HU, PL, RO).}
\input{tables/cz_hu_pl_ro_grapheme.tex}\label{tbl:cz_hu_pl_ro_grapheme}
\end{table}

\subsection{Source-target G2P mapping results}
The results on the experiments with the knowledge-based pronunciation modeling technique, where the native phonemes of the source phoneme-based acoustic models were mapped to the target phonemes in the pronunciation dictionary, are in Table~\ref{tbl:cz_phoneme} for the source language Czech, and in Table~\ref{tbl:hu_phoneme} for the source language Hungarian.
The Hungarian knowledge-based acoustic model significantly outperforms the (Hungarian grapheme-based) baseline, with an $21.1\%$ overall WER.
It is worth mentioning that the Czech speakers achieve a surprisingly low $6.4\%$ WER on the Hungarian text test set.

\begin{table}
\parbox{.45\linewidth}{
\centering
\caption{WER[\%] of Latin-Czech source-target G2P model. Acoustic model size: 76 hours.}
\input{tables/cz_phoneme.tex}\label{tbl:cz_phoneme}
}
\hfill
\parbox{.45\linewidth}{
\centering
\caption{WER[\%] of Latin-Hungarian source-target G2P model. Acoustic model size: 567 hours.}
\input{tables/hu_phoneme.tex}\label{tbl:hu_phoneme}
}
\end{table}

\subsection{USG results}
The results for the Czech-Hungarian-Polish joint acoustic model are in Table~\ref{tbl:cz_hu_pl_usg}.
We also tried adding a new source language, Romanian, to the joint USG acoustic model, which improved the results significantly, yielding to our best experimental result of an overall $20.4\%$ WER, see in Table~\ref{tbl:cz_hu_pl_ro_usg}.
The intution behind adding Romanian as a further source language is, that out of the four languages, it the most closely related one to Latin.

Additionaly, we also measured the WER on any combination of three of the four source languages, to see how each source acoustic model contributes to the joint USG model.
As Table~\ref{tbl:cz_hu_pl_ro_usg} shows, each language contributed almost evenly to the four-language USG model. To avoid over weighting, Hungarian data set was reduced to 112 hours of Broadcast News speech.  
%pool of recognizers
\begin{table}
\parbox{.45\linewidth}{
\centering
\caption{WER[\%] of USG model of Czech, Hungarian and Polish (CZ+HU+PL).}
\input{tables/cz_hu_pl_usg.tex}\label{tbl:cz_hu_pl_usg}
}
\hfill
\parbox{.45\linewidth}{
\centering
\caption{WER[\%] of USG model of Czech, Hungarian, Polish and Romanian (CZ+HU+PL+RO).}
\input{tables/cz_hu_pl_ro_usg.tex}\label{tbl:cz_hu_pl_ro_usg}
}
\end{table}
%\subsubsection{Error analysis}
%TODO: why hu is better with usg model.
%TODO: why cz is better with hu phoneme model.
%TODO: revise according to new PL results!
% ma eddig jutottam. Az alábbiakat aktualizálni, kiegészíteni kell a full magyar 4 nyelvű USG szerint. A konklúziót is!
The most striking results are the Czech speakers on the Hungarian text test set with both the knowledge-based and USG models.
We had expected the Hungarian speakers to perform better with the Hungarian knowledge-based model and Hungarian text test set setting, but in fact the phoneme mapping masked the difference between mid-front \texttt{/e:/} and open-front \texttt{/\textipa{E}/} in the pronunciation of the Hungarian speakers.
In addion to that, they were pronouncing the named entities using their native pronunciation, which also increased the WER.
%TODO: why pl wer is so high.
\subsection{Conclusions}
%TODO: to be revised
In this paper, we presented two pronunciation modeling techniques for a target-language independent medieval Latin speech recognizer to eliminate the efforts of digitizing medieval Latin charter data.
Our goal was to build an acoustic model for medieval Latin, borrowing speech data from different source languages (Czech, Hungarian, Polish and ultimately Romanian).
Our test set consisted of medieval Latin charters originating from different regions read by native speakers of the above languages.
With the objective of outperforming the monolingual grapheme-based models, we presented two approaches: knowledge-based G2P modeling, and USG modeling.
%1-sentence G2P
%1-sentence USG
The results showed that both methods outperform by large the best baseline system. 
We concluded our work with comparing the results on a by-speaker-language and by-text-origin basis, where we found speaker-language differences affecting the results.

Future research directions include acquiring a considerable amount of medieval speech and textual data, as well as implementng a more refined G2P modeling using a global pheneme inventory set.

% Bibliography
\bibliographystyle{splncs03}
\bibliography{tsd2017}

\end{document}
