%
%	TSD 2017
%	LaTeX Template for Camera-ready Version
%
%	Rel. 2013-05-20 by Ivan Habernal (habernal@kiv.zcu.cz)
%	Rel. 2014-11-21 by Kamil Ekstein (kekstein@kiv.zcu.cz)
%   Rel. 2015-02-23 by Pavel Kral    (pkral@kiv.zcu.cz)
%	Rel. 2017-02-06 by Kamil Ekstein (kekstein@kiv.zcu.cz)
%
%	Based upon Springer's LNCS series template.
%
\documentclass[runningheads,a4paper]{llncs}

\usepackage{times}
\usepackage{amssymb}
\setcounter{tocdepth}{3}
\usepackage{graphicx}
\usepackage{url}

% TSD 2017: Add any additional packages you use in your manuscript
% -----pack
% \usepackage{xxx}
% -----

% TSD 2017: Add your custom definitions etc., if required
% -----misc
% \newcommand{\xxx}[1]{[#1]}
% -----

\newcommand{\keywords}[1]{\par\addvspace\baselineskip
\noindent\keywordname\enspace\ignorespaces#1}

% TSD2017: Put your e-mail addresses here
\urldef{\mailsa}\path|{author1, author2}@institute1.org|
\urldef{\mailsb}\path|author3@institute2.org|
%\urldef{\mailsc}\path|other_mails_if_needed|    

\begin{document}

% TSD 2017: Put your title here (please, use capitalization, see e.g.
% http://en.wikibooks.org/wiki/Basic_Book_Design/Capitalizing_Words_in_Titles)
\title{Cross-Native-Language Medieval Latin Dictation}

% TSD 2017: a short form should be given in case the title is too long for the running head
\titlerunning{Cross-Native-Language Medieval Latin Dictation}

% TSD 2017: Author's names. Chinese authors should write their first names(s)
% in front of their surnames. This ensures that the names appear correctly in
% the running heads and the author index.
% If the names contain accented characters, please use escape codes
% (refer to http://en.wikibooks.org/wiki/LaTeX/Special_Characters#Escaped_codes)
\author{Firstname1 Surname1 \and Firstname2 Surname2 \and Firstname3 Surname3}

% TSD 2017: For authors from different institutions, please use the following
% form including institution reference
% \author{Firstname1 Surname1\inst{1} \and Firstname2 Surname2 \inst{2}}

% TSD 2017: Author's names for headings. For 1-2 authors, use the following form
\authorrunning{Firstname1 Surname1 and Firstname2 Surname2}
% TSD 2017: For more than 2 authors, please, use the following
% \authorrunning{Name1 Surname1 et al.}

% TSD 2017: The authors' affiliations
\institute{Affiliation1, Institute1, Address \\
% TSD 2017: optional url
\url{www.website.org} \\
\mailsa\\
% TSD 2017: For authors from different institutions, add 2nd institution, etc.
% \and
% Affiliation2, Institute2, Address \\
% \url{www.website.org} \\
% \mailsb\\
}

% TSD 2017: Put all authors' names to the proceeding index (surname, first name)
\index{Surname1, Firstname1}
\index{Surname2, Firstname2}

\toctitle{} \tocauthor{}

\maketitle

%
%
%	TSD2017 SUBMISSION TEXT
%
%
\begin{abstract}
% TSD 2017:
We present a medieval Latin charter dictation system which can be of great help for preserving language documents from the same era, since optical character recognition systems often fail to handle historic documents.
Our target era and geographical regions are medieval Latin, and documents originating from the Visegrad region, for speakers with Czech, Hungarian and Polish as their native languages.
Our baseline systems are separately trained grapheme-based acoustic models for all the above three languages. 
We introduce two pronunciation modeling techniques to outperform the separately trained models.
The first one is using grapheme-to-phoneme (G2P) mapping with Latin-specific pronunciation rules applied. 
The second one is training a Unified Simplified Grapheme (UGS) acoustic model that can deal with cross-native-langauge variations.
%In this paper, we observe
We show that our methods outperform our baseline system, reducing the WER by ...\% and ...\% respectively.
% TSD 2017: keywords, comma-separated
\keywords{pronunciation modeling, Latin, low resource speech recognition}
\end{abstract}

\section{Introduction}
Apart from the two official pronunciations of Latin (classical and ecclesiastical), many regional pronunciations exist varying accross region and era.
The third most known pronunciation group is the East-Central European (ECE) one, used for medieval Latin.
Although the target pronunciation is considered to be uniform in this region, it is also has to be taken into account that the acoustic base of the different native languages varies, which can lead to different speakers pronouncing the same words differently.
It also has to be noted, that apart from the variations in the pronunciations, orthographic and linguistic variations are also exhibited through regions.
This raises the question of how to create a dictation system which has to deal with uniform pronunciations for speakers with different native languages reading linguistically different texts.
We propose a system that is suitable for medieval Latin dictation for all speakers from the ECE region.
The system we develop is a unified/joint system that can deal with both the variability in the speakers' pronunciations when speaking medieval Latin, and the grammatical/lexical variabilities of the texts.
Our baseline system consists of separately trained grapheme (and phoneme) based acoustic models for the different languages in the ECE region.
These separately trained models work good with their respective native speakers, but perform poorly with speakers of different native languages.
We apply two different pronunciation modeling techniques to develop a models that are superior to the baseline.
The first one, dicussed in detail in Section~\ref{g2p}, is based on the assumption that 
The second method we use is USGM (Unified Simplified Grapheme Modeling), where a joint/minimal/common grapheme inventory is established for all the languages paricipating in the joint acoustic model training.
We describe this method in Section~\ref{usg}.

\subsection{Related work}
Similar work has been done for multi-dialectal languages such as Arabic in~\cite{elfeky16} where jointly trained acoustic models were outperformed by methods that unify dialect specific-acoustic models using knowledge distillation and multitask learning.

\section{Data}
\subsection{Textual data}
As part of out inquiry was to cover linguistic variability accross the ECE region, aquiring textual data posed a few challenges.
First of all, textual data are scarce for medieval Latin, and texts originating from the ECE geographical region are even more scarce.
Additionally, most of the available sources mix local languages and Latin, with no metadata to separate them.
For the scope of this paper, we collected monolingual texts only.
\subsubsection{Training data}
A smaller amount of in-domain data (medieval charters) were collected from~\cite{monasterium} (Monasterium), with and overall of 480k tokens.
These documents are originating from the Hungarian Kingdom, from 1000 to 1524 AD.
To increase the vocabulary size of the language model, we collected a relatively larger (but still small, compared to state-of-the-art language models used in speech recognition) 1.3 token corpus from~\cite{latinlibrary} (LatinLibrary).
This corpus consists of literary and historical texts from the post-classical era.
In spite of our efforts, at the time of writing this paper, we could not gather textual data from the age and area of the Kingdoms of Bohemia and Poland.
\subsubsection{Test data}
Using independent sources three-three charters were selected from the Kingdoms of Bohemia (CZ), Hungary (HU) and Poland (PL), from around 1200-1300 AD, as development and test data.
The dev set was used for evaluating the language model, and the test set to test the performance of our recognizers, by having them read out loud by historians fluent in medieval Latin.
\subsubsection{Alternate spellings}
One interesting feature of the acquired corpora is that they contain a significant number of spelling variants.
Having spelling variants in the corpus with identical pronunciation introduces noise, and thus has a negative effect on recognition results.
We obtained a unified spelling for these variants by favouring the more frequent variant in the corpus (e.g. \textit{maiestati} to \textit{majestati}).
To detect the spelling variants we took all pairs in the pronunciation dictionary whose pronunciation were identical, and used context and expert knowledge to decide whether the pair of equivalent pronunciations are spelling variants or homophones.
Where the decision was that they are spelling variants, the less frequent one was replaced by the more frequent one.
Resolving spelling variants resulted in a more consistent corpus in terms of perplexity (reducing it from 775 to 672), and reduced the OOV rate by 0.8\%.
%Thus we expected to achieve better results with a model built from the corpora where spelling variants had previously been merged.
%TODO: verbatim text excerpts (cz).
\subsubsection{Language model}
The language models we built from the two corpora were estimated with the SRI Language Modeling toolkit (SRILM)~\cite{srilm} using modified Kneser-Ney smoothing method.
After estimating the mixture parameter, linear interpolation was used.

The perplexity measures on the dev data showed that the Monasterium corpus originating from the time and era of the Hungarian Kingdom
\subsection{Speech data}
\section{Acoustic modeling}
For all the different pronunciation modeling methods, the acoustic models were trained as follows.
Mel-Frequency Cepstrum $+$ Energy features were used with Linear Discriminant Analysis (LDA) + Maximum Likelihood Linear Transformation (MLLT), with a splice context of $\pm4$ frames, 10 ms of frame shift.
$9\times40$ dimensional spliced up feature vectors served as input to the feed‒forward, 6 hidden‒layer neural network with p‒norm [16] activation function.
Prior to DNN training, a Gauss Mixture Model (GMM) pre-training was performed.
Clustering and Regression Tree (CART)~\cite{kaldi} was applied to obtain across‒word context dependent shared state phone (or graph) models and their time alignment.
The number of senones (and so the size of the DNN softmax output layer) was between 7.000 and 11.000 depending on the nature of the training data.
The size of the hidden layers was kept constantly on 2.000.
A minibatch size of 512, an initial learning rate of 0.1, and final learning rate of 0.01 was applied in 20 epochs using the KALDI toolkit~\cite{kaldi}.
\subsection{Grapheme}
For our baseline systems grapheme-based pronunciation models were used.
\subsection{Grapheme to phoneme mapping (G2P)}\label{g2p}
Using Latin-specific pronunciation rules  
\subsection{Unified Simplified Grapheme Modeling}\label{usg}
The second method we propose for cross-native-langauge Latin dictation is Unified Simplified Grapheme (USG) pronunciation modeling technique, which comes in play when joint acoustic models are being trained to support recognition across multiple languages.
\subsubsection{Unified}
These acoustic models need a unified grapheme inventory.
\subsubsection{Simplified}
\section{Experimental results}
\begin{table}
\parbox{.45\linewidth}{
\centering
\caption{Hungarian phoneme}
\input{tables/hu_phoneme.tex}
}
\hfill
\parbox{.45\linewidth}{
\centering
\caption{USG}
\input{tables/cz_hu_pl_ro_usg.tex}
}
\end{table}
\subsubsection{Error analysis}
%TODO: why hu is better with usg model.
%TODO: why cz is better with hu phoneme model.
%TODO: why pl wer is so high.
\subsection{Conclusions}
In this paper, we presented two pronunciation modeling techniques for a cross-native-language medieval Latin dictation system to eliminate the efforts of digitizing medieval Latin charter data.
With the objective of outperforming the separately trained grapheme-based models, we presented two approaches: an expert G2P modeling, and UGS modeling.
The results showed...

Future research directions include acquiring a considerable amount of medieval speech and textual data.

% Bibliography
\bibliographystyle{splncs03}
\bibliography{tsd2017}

\end{document}
